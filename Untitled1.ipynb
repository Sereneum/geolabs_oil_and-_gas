{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn joblib xgboost pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFS8Hdkv8OhK",
        "outputId": "d1876b25-300d-4818-c445-b4298b1da7cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LBhLWQE_Csz",
        "outputId": "7559aa20-d80a-4bd1-bf2a-f7ba21e61c46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZPEzlUm_INS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.externals.joblib import dump, load\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import joblib"
      ],
      "metadata": {
        "id": "iLl9jVSW8ZKM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = StandardScaler()\n",
        "# print(scaler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ouHUks_Id3",
        "outputId": "11a4807c-1eb6-4948-ed5b-e36f7cf8afda"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StandardScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmbhfQ9O6-hp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load data\n",
        "data = pd.read_csv(\"Ar_300_rough_collision.dat\", sep=\" \", header=None)\n",
        "data.columns = [\"atom_id\", \"time_stuck\", \"temperature\", \"Ux_in\", \"Uy_in\", \"Uz_in\", \"Ux_out\", \"Uy_out\", \"Uz_out\"]\n",
        "\n",
        "# Separate features and target\n",
        "X = data[[\"time_stuck\", \"temperature\", \"Ux_in\", \"Uy_in\", \"Uz_in\"]]\n",
        "y = data[[\"Ux_out\", \"Uy_out\", \"Uz_out\"]]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Define XGBoost model\n",
        "model = XGBRegressor(n_estimators=2000, learning_rate=0.01, max_depth=30, random_state=3)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred, multioutput=\"variance_weighted\")\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"R2 = {r2:.4f}, MSE = {mse:.4f}\")\n",
        "\n",
        "# Feature importances\n",
        "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "print(importances.sort_values(ascending=False))\n",
        "\n",
        "# Save model and scaler\n",
        "model.save_model(\"reflection_model_xgb_t1605.json\")\n",
        "joblib.dump(scaler, 'scaler_t1605.pkl')\n",
        "# dump(scaler, 'scaler.bin', compress=True)\n",
        "# joblib.dump(scaler, \"scaler.pkl\")"
      ]
    }
  ]
}